{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# llmcam\n",
    "\n",
    "> llm camera project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file will become your README and also the index of your documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developer Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are new to using `nbdev` here are some useful pointers to get you started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install llmcam in Development mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "# make sure llmcam package is installed in development mode\n",
    "$ pip install -e .\n",
    "\n",
    "# make changes under nbs/ directory\n",
    "# ...\n",
    "\n",
    "# compile to have changes apply to llmcam\n",
    "$ nbdev_prepare\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install latest from the GitHub [repository][repo]:\n",
    "\n",
    "```sh\n",
    "$ pip install git+https://github.com/ninjalabo/llmcam.git\n",
    "```\n",
    "\n",
    "or from [conda][conda]\n",
    "\n",
    "```sh\n",
    "$ conda install -c ninjalabo llmcam\n",
    "```\n",
    "\n",
    "or from [pypi][pypi]\n",
    "\n",
    "\n",
    "```sh\n",
    "$ pip install llmcam\n",
    "```\n",
    "\n",
    "\n",
    "[repo]: https://github.com/ninjalabo/llmcam\n",
    "[docs]: https://ninjalabo.github.io/llmcam/\n",
    "[pypi]: https://pypi.org/project/llmcam/\n",
    "[conda]: https://anaconda.org/ninjalabo/llmcam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation can be found hosted on this GitHub [repository][repo]'s [pages][docs]. Additionally you can find package manager specific guidelines on [conda][conda] and [pypi][pypi] respectively.\n",
    "\n",
    "[repo]: https://github.com/ninjalabo/llmcam\n",
    "[docs]: https://ninjalabo.github.io/llmcam/\n",
    "[pypi]: https://pypi.org/project/llmcam/\n",
    "[conda]: https://anaconda.org/ninjalabo/llmcam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In development mode, navigate to the local repository and install the editable version:\n",
    "\n",
    "```sh\n",
    "$ cd /path/to/llmcam/repository\n",
    "$ pip install -e . ['dev']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up environment with necessary variables:\n",
    "\n",
    "- `OPENAI_API_KEY`: Key for using GPT chat completion API from OpenAI.  \n",
    "- `LLMCAM_DATA`: Local directory for saving generated images to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing our modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmcam.vision.ytlive import NHsta\n",
    "from llmcam.vision.gpt4v import ask_gpt4v_about_image_file\n",
    "from llmcam.application.runner import run_llmcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=LMZQ7eFhm58\n",
      "[youtube] LMZQ7eFhm58: Downloading webpage\n",
      "[youtube] LMZQ7eFhm58: Downloading ios player API JSON\n",
      "[youtube] LMZQ7eFhm58: Downloading web creator player API JSON\n",
      "[youtube] LMZQ7eFhm58: Downloading m3u8 information\n",
      "11.11.2024 17:50:38\n",
      "cap_2024.11.11_17:58:09_unclear.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Path('../data/cap_2024.11.11_17:58:09_unclear.jpg')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "fn = NHsta()()\n",
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'timestamp': '2024-10-30T21:55:57',\n",
       " 'location': 'Tuomiokirkko',\n",
       " 'dimensions': {'width': 1280, 'height': 720},\n",
       " 'buildings': {'number_of_buildings': 15,\n",
       "  'building_height_range': '2-5 stories'},\n",
       " 'vehicles': {'number_of_vehicles': 0},\n",
       " 'waterbodies': {'visible': False},\n",
       " 'street_lights': {'number_of_street_lights': 25},\n",
       " 'people': {'approximate_number': 0},\n",
       " 'lighting': {'time_of_day': 'night', 'artificial_lighting': 'prominent'},\n",
       " 'visibility': {'clear': True},\n",
       " 'sky': {'visible': True, 'light_conditions': 'night'}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "ask_gpt4v_about_image_file(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# Start the application on port 5001\n",
    "run_llmcam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules\n",
    "\n",
    "The application consists of 4 main modules:\n",
    "\n",
    "- `core`: Core module for implementing GPT Function calling (FC)  \n",
    "- `utils`: Module for implementing utilities as compatible functions for GPT FC  \n",
    "- `vision`: Module for implementing computer vision features as compatible functions for GPT FC  \n",
    "- `application`: Module for implementing web-service "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"display: flex; justify-content: center; align-items: center; width: 100%; height: 100%;\">\n",
       "        <img src=\"https://mermaid.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\" style=\"max-width: 100%; max-height: 100%; object-fit: contain;\" />\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| echo: false\n",
    "import base64\n",
    "from IPython.display import HTML, display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def mm(graph):\n",
    "    graphbytes = graph.encode(\"utf8\")\n",
    "    base64_bytes = base64.urlsafe_b64encode(graphbytes)\n",
    "    base64_string = base64_bytes.decode(\"ascii\")\n",
    "    img_url = \"https://mermaid.ink/img/\" + base64_string\n",
    "    \n",
    "    # Responsive HTML with CSS for fitting to parent container\n",
    "    html = f\"\"\"\n",
    "    <div style=\"display: flex; justify-content: center; align-items: center; width: 100%; height: 100%;\">\n",
    "        <img src=\"{img_url}\" style=\"max-width: 100%; max-height: 100%; object-fit: contain;\" />\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(html))\n",
    "\n",
    "mm(\"\"\"\n",
    "C4Context\n",
    "  title LLMCAM layered modules\n",
    "  Enterprise_Boundary(b0, \"LLMCAM module\") {\n",
    "    System(llmcam, \"llmcam\", \"Overall 'llmcam' module\")\n",
    "\n",
    "    Container_Boundary(container_app, \"Applications\") {\n",
    "      Container(chat_ui, \"Chat UI\", \"FastHTML\", \"Builds FastHTML application for GPT Chat UI\")\n",
    "      Container(demo, \"Demo Scenarios\", \"Jupyter Notebook\", \"Example usage for 'llmcam' with demo notebooks\")\n",
    "      Container_Boundary(container_chat_ui, \"Chat UI components & utilities\") {\n",
    "        Container(runner, \"Application runner\", \"Uvicorn\", \"Simple function to start server\")\n",
    "        Container(app, \"UI application\",  \"FastHTML\", \"Implementation of routers & websockets\")\n",
    "        Container(session, \"Session\",  \"Python\", \"Session-related functions & frameworks\")\n",
    "        Rel(runner, app, \"Uses\", \"Imports\")\n",
    "        Rel(app, session, \"Uses\", \"Imports\")\n",
    "      }\n",
    "    }\n",
    "\n",
    "    Container_Boundary(container_functions, \"Functions for FC\") {\n",
    "      Container(vision, \"Vision\", \"Torch, YOLO, ...\", \"Functions for integrating computer vision\")\n",
    "      Container(utils, \"Utils\", \"Python\", \"Functions for general-purpose utilities\")\n",
    "      Container_Boundary(container_vision, \"List of functions in 'llmcam.vision'\") {\n",
    "        Container(ytlive, \"Youtube Live Capture\", \"Requests\", \"Function to capture image from youtube live\")\n",
    "        Container(gpt4v, \"Ask GPT\",  \"GPT\", \"Function to ask GPT to extract information from captured image\")\n",
    "        Container(yolo, \"YOLO\",  \"YOLO\", \"Function to detect objects with YOLO\")\n",
    "        Container(dtcam, \"DTcam\",  \"Python\", \"Function to capture image from weathercam\")\n",
    "        Container(plotting, \"Plotting\",  \"Matplotlib\", \"Function to form a plot\")\n",
    "      }\n",
    "      Container_Boundary(container_utils, \"List of functions in 'llmcam.utils'\") {\n",
    "        Container(bash_command, \"Bash Command\", \"Python\", \"Function to execute bash commands\")\n",
    "        Container(notification, \"Notification\",  \"Python\", \"Function & framework to send notifications\")\n",
    "        Container(store, \"Store\",  \"Python\", \"Function & framework to manage tools\")\n",
    "        Container(file_manager, \"File Manager\",  \"Python\", \"Function to manage local files\")\n",
    "      }\n",
    "    }\n",
    "\n",
    "    Container_Boundary(container_core, \"Core functions for building FC framework\") {\n",
    "      Container(execute, \"Execute FC\", \"Python, GPT\", \"Framework & utilities to generate GPT dialog and integrate FC\")\n",
    "      Container(function, \"Function\", \"Python\", \"Utilitlies to extract information and form schema from functions\")\n",
    "      Container(oas, \"OAS to Requests\", \"Python, requests\", \"Utilities to extract information and form schema from OAS\")\n",
    "\n",
    "      Rel(execute, function, \"Uses\", \"Imports\")\n",
    "      Rel(execute, oas, \"Uses\", \"Imports\")\n",
    "    }\n",
    "  \n",
    "    Rel(chat_ui, vision, \"Uses\", \"Imports\")\n",
    "    Rel(chat_ui, utils, \"Uses\", \"Imports\")\n",
    "    Rel(vision, execute, \"Uses\", \"Imports\")\n",
    "    Rel(utils, execute, \"Uses\", \"Imports\")\n",
    "  }\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
